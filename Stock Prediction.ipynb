{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Descriptive analysis",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from __future__ import print_function\n\n\nimport numpy as np\nimport scipy.io as sio\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n\n\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neural_network import MLPRegressor\n\n\nfrom __future__ import print_function\n\nimport os\nimport csv\nimport numpy as np\nimport scipy.io as sio\nfrom scipy import stats\nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nimport KMean_MissingImpute as KMI\nimport ModelEva",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n\nprint('Loading data...')\ndatafit = sio.loadmat('datafit.mat')\nX = datafit['X']\nY = np.squeeze(datafit['Y'])\n#Y = datafit['Y']\n\nprint('Loaded X matrix shape:', X.shape)\nprint('Loaded Y vector shape:', Y.shape)\n\nmCovX = np.corrcoef(X.T)\n\nprint('Y describe', stats.describe(Y, axis=0))\nnGlobalMin = np.amin(Y) - 0.001\nprint('Y describe', stats.describe(np.log(Y - nGlobalMin), axis=0))\nnQu = np.percentile(Y, 0.1)\nnQl = np.percentile(Y,99.9)\nindex = np.where((Y>nQu) * (Y<nQl))\nY = Y[index]\nX = X[index]\ndR = stats.describe(Y, axis=0)\nmDesarray = np.array([[dR.mean, dR.variance, dR.skewness, dR.kurtosis]])\n\nfor iCol in range(8):\n    Xp = X[:, iCol]\n    Xp = Xp[~np.isnan(Xp)]\n\n    plt.boxplot(Xp)\n    plt.show()\n    print('Col num %d' %iCol, stats.describe(Xp, axis=0))\n    dR = stats.describe(Xp, axis=0)\n    #mDesarray = np.concatenate((mDesarray, np.array([[dR.mean, dR.variance, dR.skewness, dR.kurtosis]])), axis=0)\nnp.savetxt('Description.csv', mDesarray, delimiter=',')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Missing value imputation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n\ndef kmeans_missing(X, n_clusters, max_iter=5):\n    \"\"\"Perform K-Means clustering on data with missing values.\n\n    Args:\n      X: An [n_samples, n_features] array of data to cluster.\n      n_clusters: Number of clusters to form.\n      max_iter: Maximum number of EM iterations to perform.\n\n    Returns:\n      labels: An [n_samples] vector of integer labels.\n      centroids: An [n_clusters, n_features] array of cluster centroids.\n      X_hat: Copy of X with the missing values filled in.\n    \"\"\"\n\n    # Initialize missing values to their column means\n    missing = np.isnan(X)\n    mu = np.nanmean(X, 0, keepdims = 1)\n    mu[np.isnan(mu)] = 0 #If all of one column is 0, just set it to 0\n    X_hat = np.where(missing, mu, X)\n\n    for i in range(max_iter):\n        if i > 0:\n            # initialize KMeans with the previous set of centroids. this is much\n            # faster and makes it easier to check convergence (since labels\n            # won't be permuted on every iteration), but might be more prone to\n            # getting stuck in local minima.\n            cls = KMeans(n_clusters, init= prev_centroids )\n        else:\n            # do multiple random initializations in parallel\n            cls = KMeans(n_clusters, n_jobs=1)\n\n        # perform clustering on the filled-in data\n        labels = cls.fit_predict(X_hat)\n        centroids = cls.cluster_centers_\n\n        # fill in the missing values based on their cluster centroids\n        X_hat[missing] = centroids[labels][missing]\n\n        # when the labels have stopped changing then we have converged\n        if i > 0 and np.all(labels == prev_labels):\n            break\n\n        prev_labels = labels\n        prev_centroids = cls.cluster_centers_\n\n    return labels, centroids, X_hat",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Model evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n\ndef fLoss(vTure, vPredict, nAggre = 2, nConserv = 1):\n    #vTure: true return vector\n    #vPredict: Predicted return vector\n    #nAggre: The penalty coefficient if the prediction is aggressive\n    #nConserv: The penalty coefficient if the prediction is conservative\n\n    #Returns the mean loss score of the prediction. This value is always non-nagetive\n\n    vPercentErr = (vTure - vPredict) #/ (vTure) #For percentage bias\n    iIndex = vPercentErr <= 0 #The true return is less than predicted return. So our prediction is too aggresive\n    vPercentErr[iIndex] *= -nAggre\n    iIndex = vPercentErr > 0\n    vPercentErr[iIndex] *= nConserv\n\n    return np.mean(vPercentErr)\n\ndef fModelSelection(sModel = 'Linear'):\n    #sModel: Choose different model\n\n    #Return model object\n\n    if sModel == 'Linear':# Linear model for OLS\n        model = linear_model.LinearRegression()\n    elif sModel == 'SVR': #SVM regressing\n        dParameters = {'kernel':['linear','rbf'],'C':[3,5,9], 'gamma':[0.03,0.05,0.1]} # 'poly' 'degree':[2,3,4],\n        model = GridSearchCV(SVR(), dParameters)\n    elif sModel == 'EN': # Elastic Net\n        dParameters = {'alpha': [1, 1.5, 2], 'l1_ratio' : [0.3, 0.5, 0.7]}\n        model = GridSearchCV(ElasticNet(random_state=0), dParameters)\n    elif sModel == 'MLP': # Multilayer perceptron\n        dParameters = {'alpha': [0.0001,0.001, 0.01, 0.1]}\n        model = GridSearchCV(MLPRegressor(), dParameters)\n    else:#Exception handeling\n        raise ValueError('Invalide model argument.for sModel! Your sModel is: %s' %sModel)\n    return model\n\n\ndef fForwardSelectFeature(mX,vY, sScore = 'adj_r2', nAggre = 2, nConserv = 1, sModel = 'Linear'):\n    #X: numpy array (matrix), independent variables with one column for one feature\n    #Y: numpy array (vector), dependent variables\n    #sScore: The criteria for selection, the higher the better\n    #    fLoss: Loss function I defined above\n    #    adj_r2: Adjusted R square\n\n    #Returns (current model, a list shows the feature# (column#) selected by the forwarding method, and the finial score)\n\n    lSelectedFea = []\n    lCandidateFea = list(range(mX.shape[1]))\n    nCurrentScore = -1000000.0\n    nBestScore = -1000000.0\n\n    model = fModelSelection(sModel)\n    \"\"\"\n    \"\"\"\n    #In  we do not want the loop to select features\n    if sModel == ' ':\n        model.fit(mX, vY)#This step is really slow\n        #print(model.best_estimator_.coef_)#For grid search\n        #print(model.coefs_)#For MLP\n\n        vYhat = model.predict(mX)\n        print('Parameters grid search')\n        if sScore == 'fLoss':\n            nScore = -fLoss(vY, vYhat, nAggre, nConserv)  # The highr the better. So negative\n        elif sScore == 'adj_r2':\n            nScore = r2_score(vY, vYhat)\n            print('r2: ', nScore)\n            # nScore = model.score(mXpart, vY)\n            nScore = 1.0 - ((1.0 - nScore) * (mX.shape[0] - 1.0) / ( mX.shape[0] - len(lCandidateFea) - 1.0))  # Adj R2 = 1 - (1 - R2) * (n-1)/n-k-1\n            print('adj_r2: ', nScore)\n        else:  # Exception handeling\n            raise ValueError('Invalide model argument.for sScore! Your sScore is: %s' % sScore)\n        return model, lCandidateFea, nScore\n\n\n    while lCandidateFea and nCurrentScore == nBestScore:\n        lCandidateScores = []\n        for nCandidateFea in lCandidateFea:\n            lFeatures = lSelectedFea + [nCandidateFea]\n            mXpart = np.copy(mX[:,lFeatures ])\n            model.fit(mXpart, vY)\n            vYhat = model.predict(mXpart)\n            #print('vYhat shape: ', vYhat.shape)\n\n            if sScore == 'fLoss':\n                nScore = -fLoss(vY, vYhat, nAggre, nConserv) #The highr the better. So negative\n            elif sScore == 'adj_r2':\n                nScore = r2_score(vY, vYhat)\n                #nScore = model.score(mXpart, vY)\n                nScore = 1.0 - ( (1.0 - nScore) * (mXpart.shape[0] - 1.0) / (mXpart.shape[0] - len(lFeatures)- 1.0) ) #Adj R2 = 1 - (1 - R2) * (n-1)/n-k-1\n            else:#Exception handeling\n                raise ValueError('Invalide model argument.for sScore! Your sScore is: %s' %sScore)\n\n            lCandidateScores.append((nScore, nCandidateFea))\n\n        lCandidateScores.sort(reverse=True)\n        nBestScore, nBestCandidateFea = lCandidateScores[0]#Choose the highest score and feature\n        if nCurrentScore < nBestScore:\n            lCandidateFea.remove(nBestCandidateFea)\n            lSelectedFea.append(nBestCandidateFea)\n            nCurrentScore = nBestScore\n\n\n\n    return model, lSelectedFea, nCurrentScore",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Execute the miassing value imputation and model evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print('Loading data...')\ndatafit = sio.loadmat('datafit.mat')\nX = datafit['X']\nY = np.squeeze(datafit['Y'])\n\n\nprint('Loaded X matrix shape:', X.shape)\nprint('Loaded Y vector shape:', Y.shape)\n\nprint('Number NaN values for each column after imputation')\nprint(np.sum(np.isnan(X) , axis = 0) )#Check mssing number of each column\n\n#Removing extreme values\nnQl = np.percentile(Y, 0.1)\nnQu = np.percentile(Y, 99.9)\nindex = np.where((Y>=nQl) * (Y<=nQu))\nY = Y[index]\nX = X[index]\n\n\n#Set model arguments\nsModelUse = 'EN'\nsFileName = 'flsqS1000_200'\nnTrainWindowL = 1000 #Influences the running time and preceiceness of each loop\nnTestWindowL = 200 #Influences how many loops\nnTestStart = nTrainWindowL #This is the first date in the current test window\n\nmResultIn = np.empty([1,4])\nmResult = np.empty([1,4])\nmResult = np.delete(mResult, 0, 0)\nmResultIn = np.delete(mResultIn, 0, 0)\nlFeatures = []\n\n#Moving window back testing\nwhile(nTestStart <= X.shape[0]):\n    mXtrain = X[nTestStart - nTrainWindowL : nTestStart, :]\n    mYtrain = Y[nTestStart - nTrainWindowL : nTestStart]\n    print('Imputing missing values by k-means clustering')\n    mXtrain = KMI.kmeans_missing(mXtrain, 10)[2]  # Impute missing data by k-means clustering\n\n    nTestEnd = nTestStart + nTestWindowL\n    nTestEnd = nTestEnd if nTestEnd <= X.shape[0] else X.shape[0] #If it reaches the end of the data\n    mXtest = X[nTestStart : nTestEnd, :]\n    mYtest = Y[nTestStart : nTestEnd]\n    mXtest = KMI.kmeans_missing(mXtest, 10)[2]  # Impute missing data by k-means clustering\n\n\n\n\n    #Transformation trail. The results are not good\n    nGlobalMin = np.amin(mXtrain) - 0.001\n#    mXtrain = np.concatenate((mXtrain, 1 / (mXtrain - nGlobalMin)), axis=1)\n#    mXtest = np.concatenate((mXtest, 1 / (mXtest - nGlobalMin) ), axis=1)\n    mXtrain = np.concatenate( (mXtrain, mXtrain**2, 1/(mXtrain - nGlobalMin) ), axis=1)\n    mXtest = np.concatenate((mXtest, mXtest**2, 1 / (mXtest - nGlobalMin) ), axis=1)\n\n#    mXtrain = np.log(mXtrain - nGlobalMin)\n#    mXtest = np.log(mXtest - nGlobalMin)\n\n\n#    mYtrain = 3 * mXtrain[:, 0] * 3 * mXtrain[:, 1] + 6 * mXtrain[:, 4]  #Only for test purpose\n#    mXtrain[:,1] = mYtrain Only for test purpose\n\n    #####\n    # Model here\n    print('Featu1res selection...')\n    model, lFeaS,nScore = ModelEva.fForwardSelectFeature(mXtrain, mYtrain, sScore='fLoss', nAggre = 2, nConserv = 1, sModel = sModelUse)\n    lFeaS = sorted(lFeaS)\n    print('Chose features: ',lFeaS, '\\n', 'Score: ',nScore, '\\n' )\n    mXtrain = mXtrain[:, lFeaS]\n    mXtest = mXtest[:, lFeaS]\n    print('Xshape',mXtrain.shape, mXtest.shape )\n    print('Building and training model...')\n\n    model.fit(mXtrain, mYtrain)\n    mY_hat = model.predict(mXtrain)\n    mY_pred = model.predict(mXtest)\n\n    print('Evaluate in-sample model...')\n    nLoss = ModelEva.fLoss(mYtrain, mY_hat, nAggre=2, nConserv=1)\n    r2 = r2_score(mYtrain, mY_hat)\n    r_value = np.sign(r2) * np.sqrt(abs(r2))\n    correlation = np.corrcoef(mYtrain, mY_hat)[0, 1]\n    mResultIn = np.concatenate((mResultIn, np.array([[nLoss, r2, r_value, correlation]])), axis=0)\n    print('Evaluating in-sample result', mResultIn[-1, :])\n\n    print('Evaluating model...')\n    nLoss = ModelEva.fLoss(mYtest, mY_pred, nAggre=2, nConserv=1)\n    r2 = r2_score(mYtest, mY_pred)\n    r_value = np.sign(r2) * np.sqrt(abs(r2))\n    correlation = np.corrcoef(mYtest, mY_pred)[0, 1]\n    mResult = np.concatenate((mResult, np.array([[nLoss, r2, r_value, correlation]])), axis=0)\n    print('Evaluating result',mResult[-1, :])\n\n    #####\n    #Save results for further analysis\n    lFeatures = lFeatures.insert(-1, lFeaS)\n    with open(sFileName + sModelUse + 'SelectFeatures.csv', 'w') as myfile:\n        wr = csv.writer(myfile)\n        wr.writerow(lFeatures)\n\n    np.savetxt(sFileName + sModelUse + 'Insamp.csv', mResultIn, delimiter=',')\n    np.savetxt(sFileName + sModelUse + 'Outsamp.csv', mResult, delimiter=',')\n    nTestStart = nTestEnd",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}